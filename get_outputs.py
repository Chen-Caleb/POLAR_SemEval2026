import yaml
import torch
import argparse
import pandas as pd
import numpy as np
from pathlib import Path
from torch.utils.data import Dataset
from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments

# ä»ä½ é‡æ„åçš„å·¥å…·åŒ…ä¸­å¯¼å…¥æ‰“åŒ…å‡½æ•°
from src.utils.submission_tools import generate_submission_zip


class InferenceDataset(Dataset):
    """ä¸“é—¨ç”¨äºæ¨ç†çš„æ•°æ®é›†ç±»ï¼Œå¤„ç†æ— æ ‡ç­¾çš„æƒ…å†µ"""

    def __init__(self, df, tokenizer, max_length=128):
        self.texts = df['text'].astype(str).tolist()
        self.tokenizer = tokenizer
        self.max_length = max_length

    def __len__(self):
        return len(self.texts)

    def __getitem__(self, idx):
        encoding = self.tokenizer(
            self.texts[idx],
            truncation=True,
            padding="max_length",
            max_length=self.max_length,
            return_tensors="pt"
        )
        return {k: v.squeeze(0) for k, v in encoding.items()}


def main():
    parser = argparse.ArgumentParser(description="Inference Script for POLAR SemEval 2026")
    parser.add_argument("--config", type=str, default="configs/augmented_st1.yaml", help="Path to config file")
    parser.add_argument("--checkpoint", type=str, required=True,
                        help="Path to the specific checkpoint (e.g., checkpoints/st1_baseline/final_model)")
    parser.add_argument("--task", type=str, default="st1", help="Task name (st1/st2/st3)")
    args = parser.parse_args()

    # 1. åŠ è½½é…ç½®ä¸è·¯å¾„
    with open(args.config, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)

    device = "cuda" if torch.cuda.is_available() else "cpu"
    checkpoint_path = Path(args.checkpoint)

    # 2. åŠ è½½æ¨¡å‹ä¸åˆ†è¯å™¨
    print(f"ğŸ“¦ æ­£åœ¨ä» {checkpoint_path} åŠ è½½æ¨¡å‹...")
    tokenizer = AutoTokenizer.from_pretrained(checkpoint_path)
    model = AutoModelForSequenceClassification.from_pretrained(checkpoint_path).to(device)

    # 3. åŠ è½½æµ‹è¯•/éªŒè¯æ•°æ® (ä»é…ç½®æ–‡ä»¶çš„ data è·¯å¾„è¯»å–)
    test_data_path = Path(config['data']['train_file']).parent / "dev_subtask1.jsonl"
    if not test_data_path.exists():
        # å¦‚æœè·¯å¾„ä¸å¯¹ï¼Œå°è¯•å¯»æ‰¾ data/processed/dev_subtask1.jsonl
        test_data_path = Path("data/processed/dev_subtask1.jsonl")

    print(f"ğŸ“Š æ­£åœ¨è¯»å–æ•°æ®: {test_data_path}")
    df = pd.read_json(test_data_path, lines=True)

    # 4. è®¾ç½®æ¨ç†å¼•æ“ (ä½¿ç”¨ Trainer çš„ predict æ¨¡å¼)
    dataset = InferenceDataset(df, tokenizer, max_length=config['model']['max_length'])

    # åªéœ€è¦æœ€åŸºæœ¬çš„ TrainingArguments æ¥è¿è¡Œ predict
    training_args = TrainingArguments(
        output_dir="./temp_preds",
        per_device_eval_batch_size=config['train'].get('batch_size', 32),
        fp16=torch.cuda.is_available(),
        report_to="none"
    )

    trainer = Trainer(model=model, args=training_args)

    # 5. æ‰§è¡Œæ¨ç†
    print(f"ğŸ”® æ­£åœ¨ä¸ºä»»åŠ¡ {args.task} ç”Ÿæˆé¢„æµ‹...")
    raw_output = trainer.predict(dataset)
    preds = np.argmax(raw_output.predictions, axis=-1)

    # å°†ç»“æœå¡«å› DataFrame
    df['polarization'] = preds

    # 6. è°ƒç”¨å·¥å…·å‡½æ•°ç”Ÿæˆæäº¤åŒ…
    # ç»“æœå­˜æ”¾åœ¨ outputs ç›®å½•ä¸‹
    output_zip_name = f"submission_{args.task}_v1"
    generate_submission_zip(
        df=df,
        output_dir=f"temp_{args.task}",
        zip_name=output_zip_name
    )

    print(f"\nâœ… æ¨ç†ä¸æ‰“åŒ…æµç¨‹ç»“æŸï¼")


if __name__ == "__main__":
    main()