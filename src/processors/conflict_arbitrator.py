import pandas as pd
import json
import time
import csv
from google import genai
from google.colab import userdata
from tqdm.auto import tqdm
from concurrent.futures import ThreadPoolExecutor, as_completed

# ==========================================
# 1. é…ç½®ä¸å…¨è‹±æ–‡ Prompt æ¨¡æ¿
# ==========================================
MODEL_NAME = "gemini-2.5-flash"

PROMPT_TEMPLATE = """
# Role
You are a senior sociolinguist expert specializing in global subcultures, political contexts, and internet slang.

# Task
Arbitrate "Tier 1 Conflicts" between "Human Labels" and "Model Predictions" for the SemEval 2026 Polarization Detection task.

# Context
- Objective: Identify "Polarization" (inciting conflict, discrimination, dehumanization, or radical stances).
- Conflict: Model is highly confident (conf > 0.9) but contradicts the human label.

# Input Data
- Language: {lang}
- Text: "{text}"
- Human Label: {label} (0=Neutral, 1=Polarized)
- Model Prediction: {pred}

# Reasoning Requirements
Analyze the text based on the linguistic habits of {lang}. 
Identify hidden intents like sarcasm, irony, or phonetic slurs (e.g., "é»‘ä¹è‰²" in Chinese).
The analysis MUST be in English regardless of the input text language.

# Output Format (Strict JSON, MUST be in English, Max 150 words)
{{
  "final_label": 0 or 1,
  "category": "Label Error" or "Model Bias",
  "analysis": "[Feature]: Identify key slangs or rhetoric. [Logic]: Explain the polarization logic in one sentence."
}}
"""


# ==========================================
# 2. æ ¸å¿ƒè°ƒç”¨é€»è¾‘
# ==========================================
def get_client():
    return genai.Client(api_key=userdata.get('GEMINI_API_KEY'))


def arbitrate_sample(client, row):
    """è°ƒç”¨ API å¤„ç†å•æ¡æ•°æ®å¹¶è¿”å›è§£æåçš„ JSON"""
    prompt = PROMPT_TEMPLATE.format(
        lang=row['lang'],
        text=row['text'],
        label=row['label'],
        pred=row['pred']
    )

    try:
        response = client.models.generate_content(
            model=MODEL_NAME,
            contents=prompt,
            config={
                'response_mime_type': 'application/json',
                'temperature': 0.1
            }
        )
        return json.loads(response.text)
    except Exception as e:
        return {"error": str(e)}


# ==========================================
# 3. å¤šçº¿ç¨‹å¹¶è¡Œå¤„ç†æµæ°´çº¿
# ==========================================
def run_pipeline_fast(input_file, output_file, max_workers=5, limit=None):
    # è¯»å– CSV (å¢åŠ å®¹é”™å¤„ç†)
    try:
        df = pd.read_csv(
            input_file,
            on_bad_lines='skip',  # è·³è¿‡æ ¼å¼æœ‰é—®é¢˜çš„è¡Œ
            quoting=csv.QUOTE_MINIMAL,
            escapechar='\\'
        )
    except Exception as e:
        print(f"âŒ è¯»å– CSV å¤±è´¥: {e}")
        return

    if limit:
        df = df.head(limit)

    client = get_client()
    print(f"ğŸš€ å¯åŠ¨å¹¶è¡Œå¤„ç† (çº¿ç¨‹æ•°: {max_workers})")
    print(f"ç›®æ ‡æ–‡ä»¶: {input_file}ï¼Œé¢„è®¡å¤„ç† {len(df)} æ¡æ•°æ®...")

    # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æ‰§è¡Œ
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        # å»ºç«‹ä»»åŠ¡æ˜ å°„
        future_to_row = {executor.submit(arbitrate_sample, client, row): row for _, row in df.iterrows()}

        with open(output_file, "w", encoding="utf-8") as f:
            # as_completed ä¿è¯è°å…ˆè·‘å®Œè°å…ˆå†™å…¥
            for future in tqdm(as_completed(future_to_row), total=len(df)):
                row = future_to_row[future]
                try:
                    res = future.result()

                    if "error" in res:
                        # å¦‚æœæ˜¯é¢‘ç‡é™åˆ¶æŠ¥é”™ï¼Œå»ºè®®åœ¨è¿™é‡Œå¢åŠ  time.sleep æˆ–é™ä½ max_workers
                        continue

                    # æ„é€ æœ€ç»ˆæ•°æ®æ¡ç›®
                    entry = {
                        "id": row['id'],
                        "lang": row['lang'],
                        "text": row['text'],
                        "final_label": res.get('final_label'),
                        "category": res.get('category'),
                        "analysis": res.get('analysis')  # ç¡®ä¿å­—æ®µåä¸ Prompt ä¸€è‡´
                    }

                    # å®æ—¶å†™å…¥ JSONL
                    f.write(json.dumps(entry, ensure_ascii=False) + "\n")
                except Exception as e:
                    print(f"å¤„ç† ID {row.get('id')} æ—¶å‘ç”Ÿå¼‚å¸¸: {e}")

    print(f"\nâœ… å¤„ç†å®Œæˆï¼ç»“æœä¿å­˜è‡³: {output_file}")


# ==========================================
# 4. è¿è¡Œå…¥å£
# ==========================================

# å¦‚æœä½ ä½¿ç”¨çš„æ˜¯å…è´¹ç‰ˆ API (Free Tier)ï¼Œå»ºè®® max_workers è®¾ä¸º 2 æˆ– 3
# å¦‚æœä½ ä½¿ç”¨çš„æ˜¯ä»˜è´¹ç‰ˆ API (Pay-as-you-go)ï¼Œå¯ä»¥è®¾ä¸º 10-20 ä»¥æé€Ÿå¤„ç†
run_pipeline_fast(
    input_file="ST1_Conflict_test.csv",
    output_file="Tier1_Test_Results.jsonl",
    max_workers=5
)